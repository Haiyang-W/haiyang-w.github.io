---
permalink: /
title: "About Me"
excerpt: "The main page about me."
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! I'm Haiyang Wang (Ê±™Êµ∑Ê¥ã), the final year Ph.D at Peking University, advised by [Prof. Liwei Wang](http://www.liweiwang-pku.com/). Before starting Ph.D., I completed my undergraduate studies at Zhiyuan College in Shanghai Jiaotong University.

My main research area lies in studying foundation models, such as **architecture design** and **unified modeling**.

Here are several research areas I worked on:
* Designing neural network architecture of foundation models. 
* Unified computation framework for visual modeling. 
* 3D perception (Lidar + Camera) in autonomous driving.

If you are interested in collaborating with me or want to have a chat, always feel free to contact me through e-mail.

üìù Publications
======
<sub>\* means equal contribution. See the [Publications](/publications/) page for more details. </sub>

* [GiT: Towards Generalist Vision Transformer through Universal Language Interface](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/04158.pdf).\\
**Haiyang Wang\***, Hao Tang\*, Li Jiang, Shaoshuai Shi, Muhammad Ferjad Naeem, Hongsheng Li, Bernt Schiele, Liwei Wang. In [**ECCV 2024**](https://eccv.ecva.net/Conferences/2024) (**<font color=red>Oral</font>**). \[[Code](https://github.com/Haiyang-W/GiT)\] &nbsp;<a href="https://github.com/Haiyang-W/GiT"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/Haiyang-W/GiT?style=social"> </a>
* [UniTR: A Unified and Efficient Multi-Modal Transformer for Bird's-Eye-View Representation](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_UniTR_A_Unified_and_Efficient_Multi-Modal_Transformer_for_Birds-Eye-View_Representation_ICCV_2023_paper.pdf).\\
**Haiyang Wang\***, Hao Tang\*, Shaoshuai Shi, Aoxue Li, Zhenguo Li, Bernt Schiele, Liwei Wang. In [**ICCV 2023**](https://iccv2023.thecvf.com/). \[[Code](https://github.com/Haiyang-W/UniTR)\] &nbsp;<a href="https://github.com/Haiyang-W/UniTR"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/Haiyang-W/UniTR?style=social"> </a>
* [DSVT: Dynamic Sparse Voxel Transformer with Rotated Sets](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_DSVT_Dynamic_Sparse_Voxel_Transformer_With_Rotated_Sets_CVPR_2023_paper.pdf).\\
**Haiyang Wang\***, Chen Shi\*, Shaoshuai Shi, Meng Li, Sen Wang, Di He, Bernt Schiele, Liwei Wang. In [**CVPR 2023**](https://cvpr.thecvf.com/Conferences/2023). \[[Code](https://github.com/Haiyang-W/DSVT)\] &nbsp;<a href="https://github.com/Haiyang-W/DSVT"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/Haiyang-W/DSVT?style=social"> </a>
* [CAGroup3D: Class-Aware Grouping for 3D Object Detection on Point Clouds](https://proceedings.neurips.cc/paper_files/paper/2022/file/c1aaf7c3f306fe94f77236dc0756d771-Paper-Conference.pdf).\\
**Haiyang Wang\***, Lihe Ding\*, Shaocong Dong, Shaoshuai Shi, Aoxue Li,  Jianan Li,  Zhenguo Li, Liwei Wang. In [**NeurIPS 2022**](https://neurips.cc/Conferences/2022). \[[Code](https://github.com/Haiyang-W/CAGroup3D)\] &nbsp;<a href="https://github.com/Haiyang-W/CAGroup3D"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/Haiyang-W/CAGroup3D?style=social"> </a>
* [Rbgnet: Ray-based grouping for 3d object detection](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RBGNet_Ray-Based_Grouping_for_3D_Object_Detection_CVPR_2022_paper.pdf).\\
**Haiyang Wang**, Shaoshuai Shi, Ze Yang, Rongyao Fang, Qi Qian, Hongsheng Li, Bernt Schiele, Liwei Wang. In [**CVPR 2022**](https://cvpr2022.thecvf.com/). \[[Code](https://github.com/Haiyang-W/RBGNet)\]  &nbsp;<a href="https://github.com/Haiyang-W/RBGNet"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/Haiyang-W/RBGNet?style=social"> </a>
* [Explicit shape encoding for real-time instance segmentation](https://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_Explicit_Shape_Encoding_for_Real-Time_Instance_Segmentation_ICCV_2019_paper.pdf).\\
Wenqiang Xu\*, **Haiyang Wang\***, Fubo Qi, Cewu Lu. In [**ICCV 2019**](https://iccv2019.thecvf.com/). \[[Code](https://github.com/WenqiangX/ese_seg)\] &nbsp;<a href="https://github.com/WenqiangX/ese_seg"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/WenqiangX/ese_seg?style=social"> </a>

üéñ Selected Awards
======

* **National Scholarship**, 2021-2022, 2022-2023. Awarded annually to top 1 student in all grades of Center for Data Science, Peking University. 
* **Excellent Student at Shanghai Jiaotong University**, 2020.

üè´ Professional Services
======
* Reviewer for CVPR‚Äô22-24, ECCV‚Äô22, ICML‚Äô22-24, NeurIPS‚Äô21-23, ICCV‚Äô23, IROS‚Äô23, ICLR'25.